{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS345 Fall 2024 Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Datasets\n",
    "\n",
    "* The [QSAR](http://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation) data for predicting the biochemical activity of a molecule.\n",
    "* The [Wisconsin breast cancer wisconsin dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer).\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:  choosing optimal hyperparameters\n",
    "\n",
    "Just about any machine learning algorithm has some **hyperparameters**.  These are parameters that are set by the user and are not determined as part of the training process.\n",
    "The perceptron for example, has two of those - the number of epochs and the learning rate.  For the k-nearest neighbor classifier (kNN) it's the number of neighbors, $k$, and for the linear SVM it's the soft margin constant, $C$.  Our objective in machine learning is to obtain classifiers with high accuracy, and have good estimates of how well they are performing.  In other words, we need to know how accurate a classifier would be on unseen data.  This is why we use separate test sets that the classifier has not seen for evaluating accuracy.\n",
    "\n",
    "When working with classifiers with hyperparameters you may be tempted to apply the following procedure:\n",
    "\n",
    "* Randomly split the data into separate train and test sets.\n",
    "* Loop over a list of candidate values for the hyperparameter.\n",
    "* For each value, train the classifier over the training set and evaluate its accuracy on the test set.\n",
    "* Choose the parameter value that maximizes the accuracy over the test set, and report the accuracy that you obtained.\n",
    "\n",
    "However, it turns out that this procedure is flawed, and the resulting accuracy estimate can be overly optimistic.  This is because the choice of the best performing parameter value used information about the test set: by selecting the best value according to accuracy on the test set, we use information about the labels of the test set.  Therefore, the predicted labels are based on information regarding the labels of the test set, making it so this is no longer an independent test set.\n",
    "\n",
    "Here is a better approach.  Rather than splitting the data into train and test sets, we will now split the data into three sets:  **training, validation, and test**.  The validation set will be used for evaluation of different values of the hyperparameter, leading to the following approach:\n",
    "\n",
    "* Randomly split the data into separate train, validation, and test sets (say with ratios of 0.5, 0.2, 0.3).\n",
    "* Loop over a list of candidate values for the hyperparameter.\n",
    "* For each value, train the classifier over the **training set** and evaluate its accuracy on the **validation set**. \n",
    "* Choose the best classifier, and report its accuracy over the **test set**.\n",
    "\n",
    "Your task is as follows:\n",
    "\n",
    "* Use the method described above to evaluate the accuracy of the kNN classifier over the QSAR and Wisconsin breast cancer dataset.  When iterating over the hyperparameter value $k$, use a wide range of values.  Repeat the process ten times for different data splits and report the average accuracy over the test set and the value of $k$ that was chosen most often for each dataset.  The result should be in the form of a table that shows average accuracy and most common hyperparameter value for each dataset.  We recommend using pandas to display nicely formatted tables as suggested in assignment 2.  Note that the optimal value of $k$ may vary for different splits.  Comment on your results.\n",
    "\n",
    "* Perform the same experiment for the linear SVM. In this case the soft-margin constant $C$ is the hyperparameter that requires an informed choice.  Use a wide range of values for $C$, as we have done in class.  Comment on your results.\n",
    "\n",
    "In your code, use the scikit-learn kNN and SVM implementations; you can also use the scikit-learn `train_test_split`.  When using scikit-learn's [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) class, make sure to provide the parameter `kernel=\"linear\"` so that the the resulting SVM is indeed linear; alternatively, use the [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Best Hyperparameter</th>\n",
       "      <th>Accuracy over Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.900585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.935673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.912281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>0.918129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kNN cancer</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.953216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.923977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM cancer</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.970760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.807571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.798107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.804416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.839117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.820189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.791798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.813880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.794953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.835962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>0.845426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0.880126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0.851735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.867508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.854890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>0.854890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.873817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.870662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.870662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Classifier Iteration  Best Hyperparameter  Accuracy over Test Set\n",
       "0   kNN cancer         1                    4                0.947368\n",
       "1   kNN cancer         2                    1                0.900585\n",
       "2   kNN cancer         3                   12                0.900585\n",
       "3   kNN cancer         4                    1                0.935673\n",
       "4   kNN cancer         5                    8                0.929825\n",
       "5   kNN cancer         6                    4                0.935673\n",
       "6   kNN cancer         7                    4                0.912281\n",
       "7   kNN cancer         8                    4                0.894737\n",
       "8   kNN cancer         9                   64                0.918129\n",
       "9   kNN cancer        10                    4                0.918129\n",
       "10  SVM cancer         1                   32                0.953216\n",
       "11  SVM cancer         2                   16                0.964912\n",
       "12  SVM cancer         3                    1                0.947368\n",
       "13  SVM cancer         4                    1                0.959064\n",
       "14  SVM cancer         5                    1                0.941520\n",
       "15  SVM cancer         6                    2                0.947368\n",
       "16  SVM cancer         7                   64                0.953216\n",
       "17  SVM cancer         8                  128                0.964912\n",
       "18  SVM cancer         9                   16                0.923977\n",
       "19  SVM cancer        10                    8                0.970760\n",
       "20    kNN QSAR         1                    4                0.807571\n",
       "21    kNN QSAR         2                    2                0.798107\n",
       "22    kNN QSAR         3                    4                0.804416\n",
       "23    kNN QSAR         4                    2                0.839117\n",
       "24    kNN QSAR         5                    2                0.820189\n",
       "25    kNN QSAR         6                    4                0.791798\n",
       "26    kNN QSAR         7                    2                0.813880\n",
       "27    kNN QSAR         8                    8                0.794953\n",
       "28    kNN QSAR         9                    8                0.835962\n",
       "29    kNN QSAR        10                    4                0.810726\n",
       "30    SVM QSAR         1                  512                0.845426\n",
       "31    SVM QSAR         2                  128                0.880126\n",
       "32    SVM QSAR         3                   32                0.851735\n",
       "33    SVM QSAR         4                    1                0.867508\n",
       "34    SVM QSAR         5                  256                0.854890\n",
       "35    SVM QSAR         6                    1                0.851735\n",
       "36    SVM QSAR         7                   64                0.854890\n",
       "37    SVM QSAR         8                    2                0.873817\n",
       "38    SVM QSAR         9                    8                0.870662\n",
       "39    SVM QSAR        10                    8                0.870662"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "def load_qsar():\n",
    "    qsar_filename='data/biodeg.csv'\n",
    "\n",
    "    X = pd.read_csv(qsar_filename).values\n",
    "    X = X.astype(str)\n",
    "    X = np.array([row[0].split(';') for row in X])\n",
    "    \n",
    "    y = X[:,41]\n",
    "    y[y == 'RB'] = 1\n",
    "    y[y == 'NRB'] = -1\n",
    "    y = y.astype(np.int64)\n",
    "    \n",
    "    X = np.delete(X, 41, 1)\n",
    "    X = X.astype(np.float64)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load_cancer():\n",
    "    # use the scikit-learn data loader\n",
    "    data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    y = y * 2 - 1\n",
    "    X = np.hstack([X, np.ones((len(X), 1))])\n",
    "    return X, y\n",
    "\n",
    "def run_kNN_experiment(X_in, y_in, data_name):\n",
    "    X, y = X_in, y_in\n",
    "\n",
    "    neighbors = [1,2,4,8,12,16,32,64,128,200]\n",
    "    data = []\n",
    "    best_parameter = []\n",
    "    best_accuracy = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "        accuracy = []\n",
    "        for k in neighbors:\n",
    "            kNN = KNeighborsClassifier(k)\n",
    "            kNN.fit(X_train, y_train)\n",
    "            y_pred = kNN.predict(X_valid)\n",
    "            accuracy.append(np.sum(y_pred == y_valid)/len(y_valid))\n",
    "    \n",
    "        best_parameter.append(np.argmax(accuracy))\n",
    "        kBest = KNeighborsClassifier(neighbors[np.argmax(accuracy)])\n",
    "        kBest.fit(X_train, y_train)\n",
    "        y_pred = kBest.predict(X_test)\n",
    "        best_accuracy.append(np.sum(y_pred == y_test)/len(y_test))\n",
    "        \n",
    "        data.append(['kNN ' + data_name, str(i+1), neighbors[np.argmax(accuracy)], np.sum(y_pred == y_test)/len(y_test)])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def run_SVM_experiment(X_in, y_in, data_name):\n",
    "    X, y = X_in, y_in\n",
    "\n",
    "    margins = [1,2,4,8,16,32,64,128,256,512]\n",
    "    data = []\n",
    "    best_parameter = []\n",
    "    best_accuracy = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "        accuracy = []\n",
    "        for m in margins:\n",
    "            svc = svm.SVC(kernel=\"linear\", C=m)\n",
    "            svc.fit(X_train, y_train)\n",
    "            y_pred = svc.predict(X_valid)\n",
    "            accuracy.append(np.mean(y_pred == y_valid))\n",
    "    \n",
    "        best_parameter.append(np.argmax(accuracy))\n",
    "        svcBest = svm.SVC(kernel=\"linear\", C=margins[np.argmax(accuracy)])\n",
    "        svcBest.fit(X_train, y_train)\n",
    "        y_pred = svcBest.predict(X_test)\n",
    "        best_accuracy.append(np.mean(y_pred == y_test))\n",
    "        \n",
    "        data.append(['SVM ' + data_name, str(i+1), margins[np.argmax(accuracy)], np.mean(y_pred == y_test)])\n",
    "    \n",
    "    return data\n",
    "# It works... it just takes a long time after implementing the SVM classifier (~3 second runtime without SVM, to ~588 second runtime with SVM)\n",
    "\n",
    "# Experiments for the cancer data set. \n",
    "all_data = []\n",
    "X, y = load_cancer()\n",
    "all_data = run_kNN_experiment(X, y, \"cancer\")\n",
    "all_data.extend(run_SVM_experiment(X, y, \"cancer\"))\n",
    "\n",
    "# kNN experiment for the QSAR dataset\n",
    "X, y = load_qsar()\n",
    "all_data.extend(run_kNN_experiment(X, y, \"QSAR\"))\n",
    "all_data.extend(run_SVM_experiment(X, y, \"QSAR\"))\n",
    "\n",
    "pd.DataFrame(all_data, columns = ['Classifier', 'Iteration', 'Best Hyperparameter', 'Accuracy over Test Set'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the kNN classifier prefers smaller values for its hyperparameter, the optimal parameter is almost always one of the lower 6 of the 10 values given to cycle through it minus one instance of 64.\n",
    "The SVM classifier seems to be more accepting of larger hyperparameter values, although the magority of the best hyperparameters found for SVM still tend to be on the smaller side of the values given for it to iterate over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:  PCA for removing noise from data\n",
    "\n",
    "As we have seen in class, the accuracy of the nearest neighbor classifer degrades when the data has noisy features that are not relevant to the classification problem.  To remedy this problem, we will use PCA to reduce the dimensionality of the data.\n",
    "\n",
    "Here is what you need to do:\n",
    "\n",
    "* **Classifier accuracy with and without noise**.  Use the QSAR dataset and evaluate the accuracy of the K nearest neighbors and SVM classifiers.  For simplicity, choose the values of K and $C$ that you selected in part 1.  In your experiments, standardize the dataset.  Next, add 1,000 noise features and evaluate model accuracy after doing so (use the better performing dataset between standardized / non-standardized dataset as your starting point).\n",
    "\n",
    "* **Note:** here is a code snippet for generating noise with a Gaussian distribution:\n",
    "```Python\n",
    "# generate a matrix of \"noise\" features of size N x d\n",
    "# each component of the matrix will have a normal (Gaussian) distribution\n",
    "# with mean of 0 and standard deviation equal to 0.5\n",
    "rng = np.random.default_rng(seed)\n",
    "X_noise = rng.normal(0, 0.5, size=(N, d))\n",
    "```\n",
    "\n",
    "* **Can PCA improve accuracy on noisy data?**  Next, we will see if PCA can improve the accuracy of the classifier on the data we added noise to.  Use PCA to represent the noise-added data in the space of the principal components.  Make sure the data is centered or standardized before applying PCA.  (Recall that centering refers to subtracting the mean from each feature, making it so that each feature has a mean of 0).  Note that the noise features do not need to be standardized!  Evaluate the accuracy of the KNN and SVM classifiers as you vary the number of principal components (no need to go above the original dimensionality of the dataset when doing so).  Plot the accuracy of each classifier on the test set as you vary the number of components.\n",
    "* **Discussion**.  Discuss your results:  was PCA useful for improving classifier accuracy?  Which of the two classifiers appears to be more robust to noise?  Why do you think that is the case?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Iteration</th>\n",
       "      <th>Best Hyperparameter</th>\n",
       "      <th>Accuracy over Test Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.747634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.804416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.788644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.772871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.776025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.779180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.757098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kNN QSAR</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.741325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.772871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.763407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.747634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM QSAR</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier Iteration  Best Hyperparameter  Accuracy over Test Set\n",
       "0    kNN QSAR         1                   32                0.747634\n",
       "1    kNN QSAR         2                   16                0.804416\n",
       "2    kNN QSAR         3                    8                0.788644\n",
       "3    kNN QSAR         4                    4                0.772871\n",
       "4    kNN QSAR         5                   16                0.776025\n",
       "5    kNN QSAR         6                    2                0.747634\n",
       "6    kNN QSAR         7                    2                0.776025\n",
       "7    kNN QSAR         8                   12                0.779180\n",
       "8    kNN QSAR         9                   16                0.757098\n",
       "9    kNN QSAR        10                   16                0.741325\n",
       "10   SVM QSAR         1                    1                0.769716\n",
       "11   SVM QSAR         2                    1                0.772871\n",
       "12   SVM QSAR         3                    1                0.753943\n",
       "13   SVM QSAR         4                    1                0.741325\n",
       "14   SVM QSAR         5                    1                0.763407\n",
       "15   SVM QSAR         6                    1                0.753943\n",
       "16   SVM QSAR         7                    1                0.747634\n",
       "17   SVM QSAR         8                    1                0.769716\n",
       "18   SVM QSAR         9                    1                0.779180\n",
       "19   SVM QSAR        10                    1                0.779180"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "rng = np.random.default_rng(22)\n",
    "\n",
    "def run_kNN_noise(X_in, y_in, data_name):\n",
    "    X, y = X_in, y_in\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=True, with_std=False).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X = np.hstack((X, rng.normal(0, 0.5, size=(len(X),1000))))\n",
    "    \n",
    "    neighbors = [1,2,4,8,12,16,32,64,128,200]\n",
    "    data = []\n",
    "    best_parameter = []\n",
    "    best_accuracy = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "        accuracy = []\n",
    "        for k in neighbors:\n",
    "            kNN = KNeighborsClassifier(k)\n",
    "            kNN.fit(X_train, y_train)\n",
    "            y_pred = kNN.predict(X_valid)\n",
    "            accuracy.append(np.sum(y_pred == y_valid)/len(y_valid))\n",
    "    \n",
    "        best_parameter.append(np.argmax(accuracy))\n",
    "        kBest = KNeighborsClassifier(neighbors[np.argmax(accuracy)])\n",
    "        kBest.fit(X_train, y_train)\n",
    "        y_pred = kBest.predict(X_test)\n",
    "        best_accuracy.append(np.sum(y_pred == y_test)/len(y_test))\n",
    "        \n",
    "        data.append(['kNN ' + data_name, str(i+1), neighbors[np.argmax(accuracy)], np.sum(y_pred == y_test)/len(y_test)])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def run_SVM_noise(X_in, y_in, data_name):\n",
    "    X, y = X_in, y_in\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=False).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X = np.hstack((X, rng.normal(0, 0.5, size=(len(X),1000))))\n",
    "\n",
    "    margins = [1,2,4,8,16,32,64,128,256,512]\n",
    "    data = []\n",
    "    best_parameter = []\n",
    "    best_accuracy = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle=True)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "        accuracy = []\n",
    "        for m in margins:\n",
    "            svc = svm.SVC(kernel=\"linear\", C=m)\n",
    "            svc.fit(X_train, y_train)\n",
    "            y_pred = svc.predict(X_valid)\n",
    "            accuracy.append(np.mean(y_pred == y_valid))\n",
    "    \n",
    "        best_parameter.append(np.argmax(accuracy))\n",
    "        svcBest = svm.SVC(kernel=\"linear\", C=margins[np.argmax(accuracy)])\n",
    "        svcBest.fit(X_train, y_train)\n",
    "        y_pred = svcBest.predict(X_test)\n",
    "        best_accuracy.append(np.mean(y_pred == y_test))\n",
    "        \n",
    "        data.append(['SVM ' + data_name, str(i+1), margins[np.argmax(accuracy)], np.mean(y_pred == y_test)])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def run_kNN_PCA(X_in, y_in):\n",
    "    X, y = X_in, y_in\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=True, with_std=False).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X = np.hstack((X, rng.normal(0, 0.5, size=(len(X),1000))))\n",
    "\n",
    "    pca_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "    pca_accuracy = []\n",
    "    neighbors = [1,2,4,8,12,16,32,64,128,200]\n",
    "    best_accuracy = []\n",
    "\n",
    "    for n in pca_range:\n",
    "        pca = PCA(n_components=n)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "        \n",
    "        for i in range(10):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.30, shuffle=True)\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "            accuracy = []\n",
    "            for k in neighbors:\n",
    "                kNN = KNeighborsClassifier(k)\n",
    "                kNN.fit(X_train, y_train)\n",
    "                y_pred = kNN.predict(X_valid)\n",
    "                accuracy.append(np.sum(y_pred == y_valid)/len(y_valid))\n",
    "        \n",
    "            kBest = KNeighborsClassifier(neighbors[np.argmax(accuracy)])\n",
    "            kBest.fit(X_train, y_train)\n",
    "            y_pred = kBest.predict(X_test)\n",
    "            best_accuracy.append(np.sum(y_pred == y_test)/len(y_test))\n",
    "        \n",
    "        pca_accuracy.append(np.mean(best_accuracy))\n",
    "    \n",
    "    return pca_range, pca_accuracy\n",
    "\n",
    "def run_SVM_PCA(X_in, y_in):\n",
    "    X, y = X_in, y_in\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=False).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X = np.hstack((X, rng.normal(0, 0.5, size=(len(X),1000))))\n",
    "\n",
    "    pca_range = [1,2,3,4,5,6,7,8,9,10]\n",
    "    pca_accuracy = []\n",
    "    margins = [1,2,4,8,16,32,64,128,256,512]\n",
    "    best_accuracy = []\n",
    "\n",
    "    for n in pca_range:\n",
    "        pca = PCA(n_components=n)\n",
    "        X_pca = pca.fit_transform(X)\n",
    "    \n",
    "        for i in range(10):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.30, shuffle=True)\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.30, shuffle=True)\n",
    "            accuracy = []\n",
    "            for m in margins:\n",
    "                svc = svm.SVC(kernel=\"linear\", C=m)\n",
    "                svc.fit(X_train, y_train)\n",
    "                y_pred = svc.predict(X_valid)\n",
    "                accuracy.append(np.mean(y_pred == y_valid))\n",
    "        \n",
    "            svcBest = svm.SVC(kernel=\"linear\", C=margins[np.argmax(accuracy)])\n",
    "            svcBest.fit(X_train, y_train)\n",
    "            y_pred = svcBest.predict(X_test)\n",
    "            best_accuracy.append(np.mean(y_pred == y_test))\n",
    "        \n",
    "        pca_accuracy.append(np.mean(best_accuracy))\n",
    "    \n",
    "    return pca_range, pca_accuracy\n",
    "\n",
    "# Experiments for the QSAR dataset with noise\n",
    "all_data = []\n",
    "X, y = load_qsar()\n",
    "all_data = run_kNN_noise(X, y, \"QSAR\")\n",
    "all_data.extend(run_SVM_noise(X, y, \"QSAR\"))\n",
    "\n",
    "pd.DataFrame(all_data, columns = ['Classifier', 'Iteration', 'Best Hyperparameter', 'Accuracy over Test Set'])\n",
    "\n",
    "# Experiments for the QSAR dataset with noise and using PCA\n",
    "\n",
    "# kNN_components, kNN_accuracy = run_kNN_PCA(X, y)\n",
    "# svm_components, svm_accuracy = run_SVM_PCA(X, y)\n",
    "\n",
    "# plt.plot(components_knn, accuracy_knn, label=\"kNN\", marker=\"o\")\n",
    "# plt.plot(components_svm, accuracy_svm, label=\"SVM\", marker=\"x\")\n",
    "# plt.xlabel(\"Number of Principal Components\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Accuracy vs Number of Principal Components\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code cell did not finish execution after 30+ minutes after implementing the PCA methods in run_kNN_PCA and run_SVM_PCA. I'm not sure where the hold up is as the total execution time in executing run_kNN_noise and run_SVM_noise was ~9 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code organization\n",
    "\n",
    "Both tasks in this assignment require you to run a particular experiment over multiple classifiers, datasets, or pre-processing steps.  In writing your code refrain from repeating the code over and over again.  To achieve that, decompose the task such that your code is modular and concise.  Not only will your code be more readable and elegant, this will also enable you to be more productive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3:  Use of AI and other web resources\n",
    "\n",
    "In the cell below indicate in detail how you used AI and other web resources for this assignment.  If you used AI tools, indicate how useful they were. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I mostly read up on the documentation provided for the datasets and the imported functions from scikitlearn. I also went back to several lectures to read about how to go about coding/using the methods needed for the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Report\n",
    "\n",
    "Answer the questions in the cells reserved for that purpose.\n",
    "\n",
    "### Submission\n",
    "\n",
    "Submit your report as a Jupyter notebook via Canvas.  Running the notebook should generate all the plots in your notebook.\n",
    "\n",
    "### Grading \n",
    "\n",
    "```\n",
    "Grading sheet for assignment 3\n",
    "\n",
    "Part 1:  50 points\n",
    "Model selection code for SVM/KNN (40 pts)\n",
    "Discussion of your results (5 pts)\n",
    "Code organization (5 pts)\n",
    "\n",
    "Part 2:  50 points\n",
    "Baseline SVM/KNN accuracy (10 pt)\n",
    "SVM/KNN accuracy as a function of number of PCs (25 pts)\n",
    "Discussion of your results (10 pt)\n",
    "Code organization (5 pts)\n",
    "\n",
    "Make sure you address your use of AI and web resources\n",
    "```\n",
    "\n",
    "Grading should be based on the following criteria:\n",
    "\n",
    "  * Code correctness.\n",
    "  * Code organization.  You code is well organized without unnecessary duplication.\n",
    "  * Plots and other results are well formatted and easy to understand.\n",
    "  * Interesting and meaningful observations made where requested.\n",
    "  * Notebook is readable, well-organized, and concise.\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
